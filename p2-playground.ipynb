{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3df4b85",
   "metadata": {},
   "source": [
    "### _EXACTSPACE DATA SCIENCE INTERNSHIP ASSIGNMENT_\n",
    "## __Part 2: RAG + LLM System Design__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159ccbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e68d2",
   "metadata": {},
   "source": [
    "### Workflow Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83f846",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"workflow.png\" alt=\"workflow\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3ee4d",
   "metadata": {},
   "source": [
    "The document overall contains 3 modalities: text, image & table. The idea is to sequentially store each of these inside an array. The text data is taken as is, the image data is first passed into an LLM to gets its detailed description. Similar operation is performed on table data. These are stored into the data array.<br><br>\n",
    "Next, they are divided into chunks, where the chunking strategy is...<br><br>\n",
    "These chunks are converted to vector embeddings using the sentence transformer model `all-mpnet-base-v2`, which converts the data into a 768-dimensional vector. Next, the user query is also converted into its vector using the same embedding model. Cosine similarity is performed to get the top-k indices. Using this, we retrieve the text data from the chunks array.<br><br>\n",
    "Finally, we pass the original user query and the retrived top-k text chunks and pass it into an LLM for getting the final response.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a32e9d3",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265f8b0",
   "metadata": {},
   "source": [
    ">Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from PyPDF2 import PdfMerger\n",
    "from groq import Groq\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import fitz\n",
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import base64\n",
    "import io\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b85fae",
   "metadata": {},
   "source": [
    ">Combine PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43141001",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"pdfs\"\n",
    "files_and_folders = os.listdir(folder)\n",
    "files = [f for f in files_and_folders if f.lower().endswith(\".pdf\")]\n",
    "files.sort()\n",
    "merger = PdfMerger()\n",
    "\n",
    "for pdf in files:\n",
    "    merger.append(os.path.join(folder, pdf))  \n",
    "\n",
    "merger.write(\"result.pdf\")\n",
    "merger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea0243",
   "metadata": {},
   "source": [
    "Now we have the resulting PDF with 195 pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e56033",
   "metadata": {},
   "source": [
    ">##### Data Extraction Pipeline Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9706e4",
   "metadata": {},
   "source": [
    "The idea is to ultimately save everything in text form. Text data will be extracted as it is, while the images and tables will be passed to an LLM with respective prompts to get their textual descriptions. Another important point is to maintain the sequence. For example if there is an image after a table in one page, the final `data_array` should have the image description after the table description. This is because if a table / image exists in a page, it is possible that the text surrounding that table / image serves as a description for that table / image. Therefore, maintaining the sequence can be better as this may benefit when chunking where similar information is still together.<br><br>\n",
    "On the other hand, if we maintain separate data arrays for each modality, it's possible that some context will be lost, and that retrieving the right information may be difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed1186",
   "metadata": {},
   "source": [
    "The model I'm using is the Gemma 3 12B model, sourced from Ollama. This is a locally downloaded VLM model that works pretty well with image data. A minor drawback is it's slow processing as the model needs to run locally. The specific model that I downloaded was the its quantized version (q4) to further speed up inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b91165",
   "metadata": {},
   "source": [
    "_Python class to send image data for inference._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383ed8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDescriber:\n",
    "    def __init__(self, model, system_prompt):\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.chat_history = []\n",
    "        self.url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "        if system_prompt:\n",
    "            self.chat_history.append({\"role\" : \"system\", \"content\" : system_prompt})\n",
    "        \n",
    "    def send(self, user_input, image_path = None, image_bytes = None):\n",
    "        if image_path or image_bytes:\n",
    "            return self.send_with_image(user_input, image_path, image_bytes)\n",
    "\n",
    "        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": self.chat_history,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(self.url, json = payload)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "        \n",
    "        assistant_response = response.json()[\"message\"][\"content\"]\n",
    "        self.chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        return assistant_response\n",
    "    \n",
    "    def send_with_image(self, prompt, image_path = None, image_bytes = None):\n",
    "        if image_bytes:\n",
    "            image_b64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        elif image_path:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                image_b64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "        else:\n",
    "            raise ValueError(\"Provide either image_path or image_bytes\")\n",
    "        \n",
    "        self.chat_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "            \"images\": [image_b64]\n",
    "        })\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": self.chat_history,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        response = requests.post(self.url, json=payload)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "        \n",
    "        assistant_response = response.json()[\"message\"][\"content\"]\n",
    "        self.chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a833a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image_to_base64(pil_image): # convert PIL image to base64\n",
    "    buffered = io.BytesIO()\n",
    "    pil_image.save(buffered, format = \"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70257f",
   "metadata": {},
   "source": [
    "_System prompt & model initialization for image processing._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4a6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vlm_model_name = \"gemma3:12b-it-q4_K_M\" # good accuracy, but slow\n",
    "vlm_model_name = \"gemma3:4b-it-qat\" # moderate accuracy, but faster\n",
    "vlm_sys_prompt = \"\"\"\n",
    "    You are an expert image analyzer with capabilities in visual interpretation, OCR, and technical documentation. \n",
    "\n",
    "    When analyzing images:\n",
    "    - Extract and transcribe ALL visible text, labels, numbers, and annotations exactly as shown\n",
    "    - Identify the image type (photograph, diagram, chart, screenshot, technical drawing, etc.)\n",
    "    - Describe visual elements systematically from top to bottom, left to right\n",
    "    - For technical content: explain diagrams, formulas, code, data visualizations, and their relationships\n",
    "    - For general content: describe subjects, composition, colors, context, and notable details\n",
    "    - Maintain accuracy - if something is unclear, state \"unclear\" rather than guessing\n",
    "    - Use structured formatting (headings, lists) for complex images to improve readability\n",
    "\n",
    "    Be comprehensive yet concise. Your goal is to make the image content accessible and understandable through text alone.\n",
    "\"\"\"\n",
    "vlm_model = ImageDescriber(vlm_model_name, vlm_sys_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419acac",
   "metadata": {},
   "source": [
    "_Python class to describe table data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4962c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = Groq(\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84dc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_describe_llm(llm_sys_prompt, prompt_for_llm_model):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": llm_sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt_for_llm_model}\n",
    "        ],\n",
    "        temperature = 1,\n",
    "        max_completion_tokens = 8192,\n",
    "        top_p = 1,\n",
    "        reasoning_effort = \"medium\",\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d973b",
   "metadata": {},
   "source": [
    "_Python function to extract text / image / table information sequencially._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced75f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_multimodal_data(pdf_path):\n",
    "\n",
    "    pdf_file = Path(pdf_path)\n",
    "    if not pdf_file.is_file() or pdf_file.suffix.lower() != \".pdf\":\n",
    "        raise FileNotFoundError(\"Provided file path is not a valid PDF.\")\n",
    "    \n",
    "    os.makedirs(\"images\", exist_ok = True) # make dir for images\n",
    "\n",
    "    doc = fitz.open(str(pdf_file))\n",
    "    result = []\n",
    "\n",
    "    # text extraction\n",
    "    for page_num, page in enumerate(doc, start = 1):\n",
    "        page_blocks = []\n",
    "\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0: # type 0 is text\n",
    "                text_content = \" \".join(\n",
    "                    span[\"text\"] for line in block[\"lines\"] for span in line[\"spans\"]\n",
    "                ).strip()\n",
    "                if text_content:\n",
    "                    y = block[\"bbox\"][1] # top coordinate\n",
    "                    page_blocks.append({\n",
    "                        \"type\": \"TEXT DATA\",\n",
    "                        \"page\": page_num,\n",
    "                        \"y\": y,\n",
    "                        \"content\": text_content\n",
    "                    })\n",
    "        print(f\"Text from page {page_num} extracted.\")\n",
    "\n",
    "        # table extraction    \n",
    "        try:\n",
    "            with pdfplumber.open(str(pdf_file)) as pdf:\n",
    "                pdf_page = pdf.pages[page_num - 1]\n",
    "                table_objects = pdf_page.find_tables()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read tables on page {page_num}: {e}\")\n",
    "            table_objects = []\n",
    "\n",
    "        for table_obj in table_objects:\n",
    "            if table_obj:\n",
    "                bbox = table_obj.bbox  \n",
    "                y = bbox[1]  \n",
    "                \n",
    "                table_data = table_obj.extract()\n",
    "\n",
    "                llm_sys_prompt = \"\"\"You are a technical table analysis expert. When given table data in list format:\n",
    "\n",
    "                    1. Identify and clearly state the table headers\n",
    "                    2. Analyze each row systematically, explaining the relationships between columns\n",
    "                    3. Extract key comparisons, advantages, and disadvantages\n",
    "                    4. Summarize the overall purpose and insights from the table\n",
    "                    5. Highlight patterns, trends, or notable information\n",
    "                    6. Use clear formatting with headers and bullet points for readability\n",
    "\n",
    "                    Provide comprehensive yet organized analysis that makes the table's content immediately understandable.\n",
    "                \"\"\"\n",
    "\n",
    "                prompt_for_llm_model = f\"\"\"Analyze this table data and provide a detailed description:\n",
    "\n",
    "                    Table Data:\n",
    "                    {table_data}\n",
    "\n",
    "                    Please provide:\n",
    "                    1. Table title/purpose (infer from content)\n",
    "                    2. Column headers and their meanings\n",
    "                    3. Detailed analysis of each row\n",
    "                    4. Key comparisons and insights\n",
    "                    5. Summary of main findings\n",
    "\n",
    "                    Format your response clearly with sections and bullet points. Keep it minimal.\n",
    "                \"\"\"\n",
    "                \n",
    "                table_desc = table_describe_llm(llm_sys_prompt, prompt_for_llm_model)\n",
    "                page_blocks.append({\n",
    "                    \"type\": \"TABLE DATA\",\n",
    "                    \"page\": page_num,\n",
    "                    \"y\": y,\n",
    "                    \"content\": table_desc\n",
    "                })\n",
    "        print(f\"Description for table from page {page_num} retrieved.\")\n",
    "        \n",
    "        # image extraction only for first 30 pages   \n",
    "        if page_num <= 30:   \n",
    "            image_list = page.get_images(full = True)             \n",
    "            for img_index, img in enumerate(image_list):\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                \n",
    "                img_rects = page.get_image_rects(xref)\n",
    "                y = img_rects[0].y0 if img_rects else 0\n",
    "                \n",
    "                page_text = page.get_text().strip()\n",
    "                prompt_for_vlm_model = f\"\"\"\n",
    "                    This is an image taken from a technical document. \n",
    "                    Unless it is a blank image or a logo or only text in the image,\n",
    "                    analyze this image thoroughly. Identify and transcribe:\n",
    "                        - All text, labels, and annotations\n",
    "                        - Technical diagrams, charts, or graphs\n",
    "                        - Data values, measurements, or statistics\n",
    "                        - Structural elements and their relationships\n",
    "                        - Any equations, formulas, or code\n",
    "                    Explain the purpose and context of what's shown.\n",
    "                    You may use the surrounding textual information taken from the \n",
    "                    same page as the image to get more accurate insights: {page_text}.\n",
    "                    Keep your description minimal.\"\n",
    "                \"\"\"\n",
    "                image_desc = vlm_model.send(prompt_for_vlm_model, image_bytes = image_bytes)\n",
    "                page_blocks.append({\n",
    "                    \"type\": \"IMAGE DATA\",\n",
    "                    \"page\": page_num,\n",
    "                    \"y\": y,\n",
    "                    \"content\": image_desc\n",
    "                })\n",
    "            print(f\"Description for image from page {page_num} retrieved.\")\n",
    "\n",
    "        page_blocks.sort(key = lambda b: b[\"y\"])\n",
    "        result.extend(page_blocks)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb583d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# data_array = extract_multimodal_data(r\"final.pdf\") # final.pdf is all the 11 pdf's combined into one\n",
    "data_array = extract_multimodal_data(r\"pdfs/Cyclone_Manual_removed.pdf\")\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time taken to process document: {(end - start) / 60:.2f} minutes\")\n",
    "print(len(data_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10cf20",
   "metadata": {},
   "source": [
    "_Saving the data array locally._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6bf52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_array\", \"wb\") as fp:   \n",
    "    pickle.dump(data_array, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd1a7b",
   "metadata": {},
   "source": [
    "_Loading the data array._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd3d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_array\", \"rb\") as fp:   \n",
    "    data_array = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ab4db",
   "metadata": {},
   "source": [
    "Now we make chunks. The strategy used here is overlap chunking. My plan is to have chunks of size 20 with an overlap of 10. This can be edited later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f825058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(data_array, size, overlap):\n",
    "    chunks = []\n",
    "    step = size - overlap\n",
    "\n",
    "    for i in range(0, len(data_array), step):\n",
    "        chunk = data_array[i : i + size]\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16484a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = make_chunks(data_array, 5, 2)\n",
    "chunks[0][3] == chunks[1][0] # checking if the overlap strategy worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712e9133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e8225d",
   "metadata": {},
   "source": [
    "_Converting chunks to embeddings._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa9e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834bf8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_vecs(chunks, embedding_model):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        chunk = str(chunk)\n",
    "        embedding = embedding_model.encode(chunk).reshape(1, -1)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "432d9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vecs = get_embedding_vecs(chunks, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e26601",
   "metadata": {},
   "source": [
    "_Get the user query and pass the it into the same embedding model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dfa9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(data, embedding_model):\n",
    "    return embedding_model.encode(data).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "610b0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about kice cyclone parts.\"\n",
    "query_embedding = get_query_embedding(query, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0667c",
   "metadata": {},
   "source": [
    "_Calculate cosine similarity between user query and all the embedding vectors._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6cfa767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(query_embedding, embedding_vecs):\n",
    "    scores = []\n",
    "    for i in range(len(embedding_vecs)):\n",
    "        score = dot(query_embedding, embedding_vecs[i].T) / (norm(query_embedding) * norm(embedding_vecs[i]))\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32ddac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = cosine_sim(query_embedding, embedding_vecs)\n",
    "sim_scores = [item.item() for item in sim_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2380b4f",
   "metadata": {},
   "source": [
    "_Making sure that the number of scores matches number of chunks._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1f40897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths match. Good to go.\n"
     ]
    }
   ],
   "source": [
    "if len(sim_scores) == len(chunks):\n",
    "    print(\"Lengths match. Good to go.\")\n",
    "else:\n",
    "    print(\"There is a length mismatch. Some mistake has taken place earlier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07cecc",
   "metadata": {},
   "source": [
    "_Get top-k chunk indices. Default is set to 8._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "741f7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_ids(sim_scores, k = 6):\n",
    "    sim_scores = np.array(sim_scores)\n",
    "    top_k_indices = np.argsort(sim_scores)[::-1][:k]\n",
    "    return top_k_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eccd4f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 10, 9, 4, 2, 11]\n"
     ]
    }
   ],
   "source": [
    "top_k_ids = top_k_ids(sim_scores)\n",
    "print(top_k_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317bb6a8",
   "metadata": {},
   "source": [
    "_Extract context based on top-k chunk indices._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "547a0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_context(chunks, top_k_ids):\n",
    "    final_context = []\n",
    "    for i in range(len(chunks)):\n",
    "        if i in top_k_ids:\n",
    "            final_context.append(chunks[i])\n",
    "    return str(final_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84ea5923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'type': 'TEXT DATA', 'page': 1, 'y': 731.2789916992188, 'content': 'Special execution, intended for use in potentially explosive atmosphere (zone 22) in conformity with category  3 of group II, according to the European ATEX Directive 94/9/EC. The equipment has the following marking:'}, {'type': 'TEXT DATA', 'page': 1, 'y': 758.3043823242188, 'content': 'II 3 D c'}, {'type': 'TEXT DATA', 'page': 2, 'y': 32.520328521728516, 'content': 'G eneral  I nformation  C ontinued'}, {'type': 'TEXT DATA', 'page': 2, 'y': 68.52032470703125, 'content': 'M odel   and  S erial  N umber The Kice Cyclone model and serial number can be found stamped on the metal identification plate located  near the horizontal inlet of the Cyclone (just behind the air inlet flange).'}, {'type': 'IMAGE DATA', 'page': 2, 'y': 107.96121215820312, 'content': 'Here’s an analysis of the image, incorporating the surrounding text:\\n\\n**Image Type:** Technical Illustration – Identification Plate Section\\n**Overall Description:**\\nThe image depicts a portion of a metal identification plate, likely affixed to a Kice Cyclone unit. The plate displays key identifiers.\\n\\n**Detailed Breakdown:**\\n*   **Text Transcription:**\\n    *   “Model”\\n    *   “Serial Number”\\n*   **Data Values/Information:** The surrounding text indicates that the \"Model\" and \"Serial Number\" are found on this plate.\\n\\n**Contextual Explanation:**\\nThis image is sourced from a Kice Industries document detailing information regarding their Cyclone collectors. The text emphasizes that the “Model” and “Serial Number” are located on the metal identification plate. This plate serves as a critical element for identifying the specific unit and ensuring proper service and part replacement.'}], [{'type': 'TEXT DATA', 'page': 2, 'y': 276.142578125, 'content': 'Identification Plate Examples'}, {'type': 'TEXT DATA', 'page': 2, 'y': 302.5926818847656, 'content': 'K ice  C yclone  P arts   and  S ervices'}, {'type': 'TEXT DATA', 'page': 2, 'y': 331.34259033203125, 'content': 'Use original Kice Cyclone replacement parts only.  These parts are available from Kice Industries, Inc.  To  obtain prompt, efficient service, always provide the following information when ordering parts:'}, {'type': 'TEXT DATA', 'page': 2, 'y': 370.9425964355469, 'content': '1.\\t Correct model number 2.\\t Correct serial number'}, {'type': 'TEXT DATA', 'page': 2, 'y': 410.5426025390625, 'content': 'For assistance in service or ordering parts, contact the customer service department at Kice Industries,  Inc., 5500 Mill Heights Drive, Wichita, KS 67219-2358, Phone 316-744-7151, and Fax 316-744-7355.'}], [{'type': 'TEXT DATA', 'page': 2, 'y': 529.392578125, 'content': 'F or  M otor   and  S peed  R educer  P arts   and  S ervice'}, {'type': 'TEXT DATA', 'page': 2, 'y': 558.1426391601562, 'content': 'Any motor or speed reducer associated with the Kice Cyclones is covered by the manufacturer’s warranty.   If there is a problem, check with the local supplier or service representative.'}, {'type': 'TEXT DATA', 'page': 2, 'y': 754.742919921875, 'content': '5 K ice  I ndustries , I nc .'}, {'type': 'TEXT DATA', 'page': 3, 'y': 32.520328521728516, 'content': 'C yclone  I nformation   and  O perating  I nstructions  C ontinued'}, {'type': 'TEXT DATA', 'page': 3, 'y': 68.94229888916016, 'content': 'NOTE:  To ensure proper operation and optimum cyclone efficiency, inlet and outlet ductwork design is  critical.  The ductwork should have a length of straight section from the inlet and outlet of the cyclone that is  at least five times the diameter of the duct.  If this not possible, elbows in the ductwork should be oriented  in a manner that refrains from countering the air rotation inside the cyclone.  This will help maintain  efficiency.  Some acceptable examples include:'}], [{'type': 'TEXT DATA', 'page': 3, 'y': 342.0105895996094, 'content': 'An unacceptable example would include:'}, {'type': 'TEXT DATA', 'page': 3, 'y': 554.7489013671875, 'content': 'Also to ensure proper rotation, verify the cyclone outlet is opposite the inlet on the cyclone body as  shown in the above figures.'}, {'type': 'TEXT DATA', 'page': 3, 'y': 754.7430419921875, 'content': '10 K ice  I ndustries , I nc .'}, {'type': 'TEXT DATA', 'page': 4, 'y': 32.520328521728516, 'content': '5. C yclone  M aintenance  C ontinued'}, {'type': 'TEXT DATA', 'page': 4, 'y': 68.94229888916016, 'content': '1.\\t The cyclone inlet, barrel and cone for signs of wear and damage. 2.\\t The cyclone door & connections (if equipped) for a proper seal. 3.\\t The proper function of the rotary airlock valve attached to the cyclone, to verify that material is  adequately removed to maintain cyclone efficiency.  The airlock may need to be inspected for signs  of wear (see rotary airlock manual). 4.\\t Material buildup inside the cyclone which may affect function and efficiency.'}], [{'type': 'TEXT DATA', 'page': 4, 'y': 32.520328521728516, 'content': '5. C yclone  M aintenance  C ontinued'}, {'type': 'TEXT DATA', 'page': 4, 'y': 68.94229888916016, 'content': '1.\\t The cyclone inlet, barrel and cone for signs of wear and damage. 2.\\t The cyclone door & connections (if equipped) for a proper seal. 3.\\t The proper function of the rotary airlock valve attached to the cyclone, to verify that material is  adequately removed to maintain cyclone efficiency.  The airlock may need to be inspected for signs  of wear (see rotary airlock manual). 4.\\t Material buildup inside the cyclone which may affect function and efficiency.'}, {'type': 'TEXT DATA', 'page': 4, 'y': 161.34239196777344, 'content': 'Painted surfaces must be cleaned by means of vacuuming and with an anti-static cloth.   As a means to verify or troubleshoot cyclone efficiency, air volume can be measured and checked against  the air system specifications as well.'}, {'type': 'TEXT DATA', 'page': 4, 'y': 214.14244079589844, 'content': 'If heavy machine components must be dismantled to carry out service and maintenance activities, suitable  lifting equipment must be used.  Use the proper hardware torque values listed at the end of this manual for  all maintenance and installation activity.'}, {'type': 'TEXT DATA', 'page': 4, 'y': 268.30029296875, 'content': '6. S pecial  ATEX I nformation'}], [{'type': 'TEXT DATA', 'page': 4, 'y': 214.14244079589844, 'content': 'If heavy machine components must be dismantled to carry out service and maintenance activities, suitable  lifting equipment must be used.  Use the proper hardware torque values listed at the end of this manual for  all maintenance and installation activity.'}, {'type': 'TEXT DATA', 'page': 4, 'y': 268.30029296875, 'content': '6. S pecial  ATEX I nformation'}, {'type': 'TEXT DATA', 'page': 4, 'y': 301.7422790527344, 'content': 'The Cyclone is intended for use in areas in which explosive atmospheres caused by air/dusts mixtures are  unlikely to occur or, if they do occur, are likely to do so only infrequently and for a short period only.'}, {'type': 'TEXT DATA', 'page': 4, 'y': 341.4302978515625, 'content': 'When installing any electric or non-electric equipment on the cyclone, be sure that all those components  are suitable for being operated in zone 22, meaning they must fulfill the ATEX-requirements for Group II  category 3D equipment.'}, {'type': 'TABLE DATA', 'page': 4, 'y': 396.5083, 'content': '**Table Title / Purpose**  \\n*Guidelines for preventing hazardous situations during the installation and initial start‑up of a cyclone (explosion‑protected equipment).*\\n\\n---\\n\\n## 1. Column Headers & Meaning  \\n\\n| Header (as shown) | What it Represents |\\n|-------------------|--------------------|\\n| **Potentially dangerous situation during installation and initial start up** | Specific risk or unsafe condition that could arise while the cyclone is being moved, assembled, or commissioned. |\\n| **Measures that must be applied by the user during installation and initial start up** | Required safety actions, controls, or procedures the installer must follow to eliminate or mitigate the listed risk. |\\n\\n---\\n\\n## 2. Row‑by‑Row Analysis  \\n\\n| # | Hazard (Column\\u202f1) | Required Measure (Column\\u202f2) | Relationship & Rationale |\\n|---|-------------------|-----------------------------|--------------------------|\\n| 1 | **Sparking in the event of transport accidents** | • Do **not drop** the cyclone or any of its components during transport.<br>• Reason: Dropping can cause mechanical impact → spark generation → ignition of any flammable atmosphere. |\\n| 2 | **Welding as a source of sparks** | • **Prohibit welding** in explosive atmospheres (zones\\u202f0,\\u202f1,\\u202f2).<br>• Use **bolted connections** instead of welded joints. |\\n| 3 | **Use of non‑explosion‑protected tools when dismantling/assembling** | • Only **explosion‑protected, non‑sparking tools** may be used.<br>• Rationale: Conventional tools can produce sparks or hot surfaces that could ignite a hazardous atmosphere. |\\n| 4 | **Build‑up of electrostatic charges on non‑earthed enclosure parts** | • Connect an **external grounding wire** to the cyclone during on‑site installation.<br>• Grounding dissipates static charge, preventing discharge sparks. |\\n\\n*Each row pairs a specific source of ignition (spark, static, hot work) with a concrete control that removes or isolates that source.*\\n\\n---\\n\\n## 3. Key Comparisons & Insights  \\n\\n- **Common Theme:** All hazards involve **potential ignition sources** (mechanical sparks, welding arcs, tool‑generated sparks, electrostatic discharge).  \\n- **Control Strategy:** The table consistently recommends **elimination of spark‑producing actions** (no dropping, no welding, use of non‑sparking tools) and **passive protection** (grounding).  \\n- **Regulatory Alignment:** Measures echo typical ATEX/IECEx requirements for equipment in **Explosion Zones 0‑2** (e.g., “no hot work”, “use explosion‑protected tools”).  \\n- **Priority Order:**  \\n  1. **Physical handling** (drop‑avoidance) – first line of defense during transport.  \\n  2. **Work‑method restrictions** (no welding, use bolts).  \\n  3. **Tool selection** (explosion‑protected only).  \\n  4. **Electro‑static control** (grounding).  \\n\\n---\\n\\n## 4. Summary of Main Findings  \\n\\n- The table serves as a **quick‑reference checklist** for installers to avoid ignition sources when commissioning a cyclone in hazardous (explosive) atmospheres.  \\n- All recommended measures focus on **spark prevention** and **electro‑static discharge mitigation**.  \\n- Implementation of these controls ensures compliance with explosion‑protection standards and protects personnel and equipment from fire or explosion during the critical installation/start‑up phase.  \\n\\n---  \\n\\n**Take‑away:** Follow the checklist verbatim—no dropping, no welding, only explosion‑rated tools, and always ground the enclosure—to maintain a safe installation environment for cyclone equipment in explosive zones.'}]]\n"
     ]
    }
   ],
   "source": [
    "final_context = get_final_context(chunks, top_k_ids)\n",
    "print(final_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a1092",
   "metadata": {},
   "source": [
    "Now for the final step, we make a function the an LLM that will answer the user query based on all the context that has been extracted. The prompt engineering here is very crucial as the LLM must know how all the information has been extracted and how the context is formatted.<br><br>\n",
    "We will be using the LLM `gpt-oss-120b`, sourced form Groq cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eaba8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_llm_sys_prompt = \"\"\"You are a document assistant. Answer the user query using only the provided context.\n",
    "\n",
    "    The context contains text, tables, and images with y-axis coordinates indicating their position on the page.\n",
    "\n",
    "    **Instructions:**\n",
    "    - Answer accurately based on the context\n",
    "    - If information is insufficient, state this clearly\n",
    "    - Use y-coordinates to understand content order and relationships\n",
    "    - Consider all content types (text, tables, images) together\n",
    "    - Keep the answers as brief as possible while keeping necessary information.\n",
    "\n",
    "    **Reference Format:**\n",
    "    At the end of your answer, provide references in this exact format:\n",
    "\n",
    "    References:\n",
    "    - [Content Type: text/table/image, Page number: {value}]\n",
    "    - [Content Type: text/table/image, Page number: {value}]\n",
    "\n",
    "    Only include references for content you actually used in your answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "efd6c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna(final_llm_sys_prompt, context, query):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": final_llm_sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Based on the context: {context} \\n\\n Answer the question: {query}\"\"\"}\n",
    "            ],\n",
    "        temperature = 1,\n",
    "        max_completion_tokens = 8192,\n",
    "        top_p = 1,\n",
    "        reasoning_effort = \"medium\",\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "825aac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about kice cyclone parts.\n",
      "Response: Kice Cyclone units are serviced with **original Kice replacement parts only**. The model and serial number of each cyclone are stamped on the metal identification plate (located just behind the air‑inlet flange), and these numbers must be provided when ordering parts.  \n",
      "\n",
      "When you request parts you should give:\n",
      "\n",
      "1. the correct **model number**  \n",
      "2. the correct **serial number**  \n",
      "\n",
      "and contact Kice Industries’ customer‑service department (5500 Mill Heights Drive, Wichita, KS 67219‑2358; Phone 316‑744‑7151; Fax 316‑744‑7355) to obtain the appropriate components【Content Type: text, Page number: 2】.\n",
      "\n",
      "The parts catalogue includes:\n",
      "\n",
      "* **General cyclone components** – listed under “Kice Cyclone Parts and Services”.  \n",
      "* **Motor and speed‑reducer parts** – these are covered by the manufacturer’s warranty; if a problem arises you should check with the local supplier or service representative【Content Type: text, Page number: 2】.  \n",
      "\n",
      "Overall, Kice emphasizes that only genuine Kice parts should be used, and that providing the exact model and serial numbers ensures you receive the correct replacement items.  \n",
      "\n",
      "**References**  \n",
      "- [Content Type: text, Page number: 2] (Identification plate, model/serial info, ordering instructions)  \n",
      "- [Content Type: text, Page number: 2] (Kice Cyclone Parts and Services)  \n",
      "- [Content Type: text, Page number: 2] (Motor and Speed Reducer Parts and Service)\n"
     ]
    }
   ],
   "source": [
    "final_answer = qna(final_llm_sys_prompt, final_context, query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {final_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exact-space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
